{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU7JxGVEazvH"
      },
      "outputs": [],
      "source": [
        "\n",
        "#pip install transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688,
          "referenced_widgets": [
            "deb68a9e43ab4da0b2725050d4b035dc",
            "b1ac9935da43433eabb6f8f447c83a37",
            "0a778570652d4d5383d676200fa07357",
            "17e33c6d6c0141c1b29b2f349492f037",
            "70797ead07454437b1f92d5d1e7205c1",
            "8e66c04ee4554b2a86a35192b5cf355c",
            "61649806c4ff44c78cde6075eb1d32a8",
            "9067d3505fbe4fe7976e0a27f41b5897",
            "c08c5a0b9df14d98996bbb6013a6f611",
            "df64d4ac99d54d8c97d64bba7b19b249",
            "4bdc86f479f342d29ee4063e4eb8d723",
            "cb686c26044b4e4f84307b67a5927cba",
            "bf52d36788e14381a957d3f2a2cda9dd",
            "a27a763ac2ea43bb9244dd643a03e9ac",
            "6b75f639f688440dafee1b43a6cbafb5",
            "c1a535f2417a4727b5cb84c2b23ab653",
            "acb3204401b048ab9ba5135fdf116606",
            "4c99d2d1bc924156b8c291ce5a907fe1",
            "260f935e195c41d59803719d5e831c08",
            "ff186f29e3e647eebb5ba4ba871dd3dd",
            "c6441e7b309f4deb8c8c77e1e1020d04",
            "c7228fe117c64d8dbade0a3583aab25a",
            "8a38258292ad4f9fb94a06b3ac5364cc",
            "75d1bbba184f412193978d2ccb1c37d3",
            "e6d8be38e1404affa3b0c97aa0f661be",
            "5172520e0dc2424f8bc2528fc5200731",
            "3a177015a9f448adb446822e300b27e0",
            "852d9dce94ec4fff82901e245418bb14",
            "a882046601b94ca18304189c29c2dc26",
            "32b4b7d30345454ca69ff2b2cd34d9a6",
            "0417a7aa48234006b34ce621d212a0bf",
            "ac871bd3f24242f88b56e6c9eadcf1c8",
            "cb79145f2d18454498b9570ab870d221",
            "4993b1a228dd47dca2efacb32a8291ab",
            "7aeb82cebe8e4469b71d0f6d2b2649a0",
            "1e7ca33c55c744c6bdbc7b0649a3ec12",
            "d9a70b4e8cfc4c6997c23719bc4e9f45",
            "977cb4ac61ba45938206a265904d1f71",
            "7f193cbb0e39455687ee43d94f484096",
            "fe3984e167f64e1e844b72d722454fe2",
            "4dedc489302d49f3b950bbdf3b1b5650",
            "fa3f1a25bc5a4871907e4f8f6dd5c914",
            "ab2cef15009f4b519b78c52c1f95d521",
            "ebfcaaa9d4fc4bdf96c73cabcbbc3a5d",
            "de883322bd26407a97f513dd50a6002a",
            "45d172cf14234a0583a3ec8d0d728815",
            "4b2489f3944d4feb8a12ddcf3d3c02c0",
            "85b8ff8a6bb0453a9b45505b4890341c",
            "360ae18f485a4ee88e414854a7cffd4c",
            "786e23c9a8934dc38edaf84fdf495721",
            "f4a469219f6d4d8ba69fcfbdba42fd96",
            "19b6bf5e117142b8893ec0d0862d08d5",
            "4deeb8a84f8444a386756693aca7985a",
            "c2f923e2f15c4fbd875c8b56f0068c27",
            "86b82d5bb79d4b889b2f730115058f1f",
            "93e0a51a47ac49ffabad0bc888b1f6bd",
            "2f40986e9eeb487cbe71b18ae6a0d8fb",
            "e55099b58d454591becddc6082d62f2a",
            "e76149e9de7c48b9b7603e0b0fcb1b60",
            "ec00979e3d954ef19d41965e666d5fe5",
            "b812d1c5486b4b3ba61f6333f69a0c64",
            "cf44b7ceecb14f908f6187eacb1d224c",
            "98dcc49d8d554fa3806f7d5e03dcb004",
            "f02a16df220d4a73b8e34d892923db0d",
            "1fd5a96f663f4134b09bfad66c7cd18b",
            "352a83415f824b7fa15b397d1164201c",
            "2e8cd44cc2224928ac8c3190908a46ff",
            "ba56941754bd47e4b971eea7a292e874",
            "b78dfd386bc64e0caae0ab9132a52889",
            "68484767c72b45e9be109ef616c784c9",
            "f5b9fae2a9be4f1899d04b207b41ad64",
            "bc90bd328fe9438e85663660fb6ce3c2",
            "2843bf4442914281abb1739df3a8cc46",
            "7909e4e1377045e487cbc4eb8802095f",
            "2cea303184d3458b90c8224cf57c6791",
            "6f205484412745528da5cfc88455969e",
            "f82d1706b362482aa7f2118ddc404105"
          ]
        },
        "executionInfo": {
          "elapsed": 4976,
          "status": "ok",
          "timestamp": 1763967042278,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "N-hgRSH59niX",
        "outputId": "fc165510-a0cd-44ea-f890-3939bec79de9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deb68a9e43ab4da0b2725050d4b035dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb686c26044b4e4f84307b67a5927cba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a38258292ad4f9fb94a06b3ac5364cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(\u2026):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4993b1a228dd47dca2efacb32a8291ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de883322bd26407a97f513dd50a6002a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93e0a51a47ac49ffabad0bc888b1f6bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e8cd44cc2224928ac8c3190908a46ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets=load_dataset(\"imdb\")\n",
        "print(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c700d57ba81d4dfba39bcc02c6222432",
            "f66d46a53d194f4181b120ac94e13b4f",
            "ac1e2064d3c54db5949fefe58d4aaa1f",
            "a009c1c715bd49e9979e787330d83001",
            "c72e586088164abf8e35d11b13926868",
            "b73b342f420b40ce87adbdc8d4eb7018",
            "15ba593e93724657b0bb276f2583e35f",
            "bb5033b6a70440c2bf48d5d19225cf9d",
            "28bb847ed85749548aaa5bf746522395",
            "ce905449f9c4425588b239126107a373",
            "fab25ca9d9674b32b330a10228290ffb",
            "439a54ff969f432babdd40b5784c2572",
            "5bf0f46d21574ca5993137294a31b345",
            "1bc0429155494a108e97e0b37a0ba060",
            "5a4b26d57a9e44eea6774f816b8933c3",
            "6f58093ba3c74c41a29432a9cdbc2147",
            "5e82c84b06424109ab1d34de90bdd2e6",
            "ba107cc39557401a81ffff8796858a1e",
            "978891637efa483c9a3522e4d54b7536",
            "19f9ee9c827b4f0cbf33875e028f3859",
            "46e0d21d35aa445094d244d68255a5f7",
            "c8571c72d09d4c898a1b8ec4547b48c7",
            "91abbaab801c4416a4a1160463084f4d",
            "8e19dea014ff4651bda825caf3c03662",
            "6ce320102e214dc0a86a26e1630b7265",
            "80b7ef508a614cdea1eedfad5842bbdf",
            "4492e60d07694c2d8465fd3a5340eb3f",
            "68f4efbbcf1e4b7fad175cdf2b773727",
            "93e7f85f28074308a7665b0649bde7db",
            "b2c70749aa754575b8a4417e594d0aeb",
            "72fff88539544f36b36583e1f09c8f09",
            "e9baca680cd04989a0cca142053a1308",
            "9e9a3de1173342c29b977462f59af15f"
          ]
        },
        "executionInfo": {
          "elapsed": 115553,
          "status": "ok",
          "timestamp": 1763967161222,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "Vo-aptLi6q6-",
        "outputId": "6fb6838b-7f61-4e9d-a558-89a5f9fe2fe6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c700d57ba81d4dfba39bcc02c6222432"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "439a54ff969f432babdd40b5784c2572"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91abbaab801c4416a4a1160463084f4d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#load tikenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples['text'],padding=\"max_length\",truncation=True)\n",
        "\n",
        "# Apply the function to the dataset\n",
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 15,
          "status": "ok",
          "timestamp": 1763967168492,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "dpPVsu-V_TMo",
        "outputId": "7564587b-9958-4944-ae48-7cb3c0355c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_datasets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9BK3c43_cnz"
      },
      "source": [
        "Handling Imbalance data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e2oB36DW_gNv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967172339,
          "user_tz": -345,
          "elapsed": 567,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader,WeightedRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "labels=tokenized_datasets['train']['label']\n",
        "class_weights=1/np.bincount(labels)\n",
        "sample_weights=[class_weights[label] for label in labels]\n",
        "\n",
        "# Create sampler\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "# Use in DataLoader\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], sampler=sampler, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmIfcw87Xc2Q"
      },
      "source": [
        "Handling noisy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 14769,
          "status": "ok",
          "timestamp": 1763967206348,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "zT0uk68FZzjN",
        "outputId": "32290acb-55ec-4357-cba7-16659cad09ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=c6e3196b9d2c3a0d9136500f9d0a569d0ee268cfca125a940403d45330093f39\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jme60bGDaSsa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967209651,
          "user_tz": -345,
          "elapsed": 761,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langdetect import detect\n",
        "def clean_text(text):\n",
        "    # Remove special characters and multiple spaces\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text if detect(text) == \"en\" else None\n",
        "\n",
        "raw_datasets = [clean_text(t) for t in raw_datasets]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSdYIWGmbWs-"
      },
      "source": [
        "Using Streaming mode to save memory bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 42720,
          "status": "ok",
          "timestamp": 1763967263001,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "v_f2fOjRhlqp",
        "outputId": "f1469576-734b-45da-a4f8-01c8a4be5521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deeplearning',\n",
              " 'SE PROJECT REPORT For Kicks (1).docx',\n",
              " 'SE PROJECT REPORT For Kicks.docx',\n",
              " 'assessment.gdoc',\n",
              " 'Untitled document (4).gdoc',\n",
              " 'API.gdoc',\n",
              " 'Untitled document (3).gdoc',\n",
              " 'FYP.docx',\n",
              " 'Copy of Roadmap.gdoc',\n",
              " 'Untitled document (2).gdoc',\n",
              " 'react.gdoc',\n",
              " 'Colab Notebooks',\n",
              " 'twitter_training.csv',\n",
              " 'cleaned_dataset_binary.csv',\n",
              " 'Untitled document (1).gdoc',\n",
              " 'Untitled document.gdoc']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check your files\n",
        "import os\n",
        "os.listdir('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "f928849ac67c4884afb6ca93f61b4ddb",
            "43f6057c3e3e447680192d152ff3e357",
            "8be11470fc0449f886f1780a5e4023e9",
            "56d93689b7704512901eda0eb348f6e7",
            "1a40aa446de9418fa8d439eeb5ea3d1f",
            "4eb9a3f9cedf448c9bb8ae8834d19879",
            "ab175aad37704533b6f429884bf469fa",
            "9a4aac390e3a4d4c8f132807b0301ddd",
            "2a5150ed6a8d41778bdf37159a11dd2a",
            "45f6e3fac62b4a5785c45e89c4adcb9a",
            "567646ecb0bd415a826900a288c3e7c4"
          ]
        },
        "executionInfo": {
          "elapsed": 1599,
          "status": "ok",
          "timestamp": 1763967272992,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "Xj7YMZhmbdb-",
        "outputId": "aaed0431-2729-4846-c948-d59a5b15a50a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f928849ac67c4884afb6ca93f61b4ddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 43374\n",
            "    })\n",
            "})\n",
            "{'text': 'I am coming to the borders and I will kill you all,', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "dataset=load_dataset(\"csv\",data_files=\"/content/drive/MyDrive/cleaned_dataset_binary.csv\")\n",
        "# Check the structure\n",
        "print(dataset)\n",
        "print(dataset['train'][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1763967277227,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "Fg9pZqCUqwWl",
        "outputId": "c5b654e0-c6f1-404a-bbf7-ab21ed3e7c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'label']\n"
          ]
        }
      ],
      "source": [
        "# See column names\n",
        "print(dataset['train'].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIPq8yBfcQts"
      },
      "source": [
        "Streaming mode (streaming=True) loads data one example at a time instead of loading everything into memory at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwrxNFErEb7"
      },
      "source": [
        "MODEL FINE TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NLHvA9rJuArm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967279733,
          "user_tz": -345,
          "elapsed": 18,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 830,
          "status": "ok",
          "timestamp": 1763967282047,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "lS7rbXaYrGUx",
        "outputId": "b71e04f8-56cb-4d02-8b1b-068911ae5bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model=AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6REOKPxDSZn"
      },
      "source": [
        "**load_best_model_at_end=True**\n",
        "\n",
        "When you train a model using the Hugging Face Trainer, the model is saved several times usually once per epoch (depending on save_strategy).\n",
        "\n",
        "But those saved models are not all equally good. Some epochs perform better than others on the evaluation dataset.\n",
        "\n",
        "So:\n",
        "\n",
        "**load_best_model_at_end=True means:**\n",
        "\n",
        "After training finishes, automatically load the checkpoint that achieved the best evaluation score, not the final epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q6cVrNxFbM1"
      },
      "source": [
        "When you run:\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "The Trainer looks at the settings in training_args and does the following:\n",
        "\n",
        "Saves checkpoints inside /results/\n",
        "(because you set output_dir=\"./results\")\n",
        "\n",
        "Evaluates after every epoch (because of evaluation_strategy=\"epoch\")\n",
        "\n",
        "Saves only one best model\n",
        "(because of save_total_limit=1)\n",
        "\n",
        "Loads the best checkpoint at the end (because of load_best_model_at_end=True)\n",
        "\n",
        "Logs training progress to /logs/(because of logging_dir=\"./logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 39,
          "status": "ok",
          "timestamp": 1763967286917,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "XFhDl8nM6uAh",
        "outputId": "e06667dc-03d1-4090-a0e8-cb14fbdd81bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.57.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 125,
          "status": "ok",
          "timestamp": 1763967293253,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "q5466zzb1-Hs",
        "outputId": "f8b5fd44-7d24-41f7-bc3c-33335085b674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load pre-trained BERT for binary classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2  # Adjust this for multi-class sentiment tasks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1763967296398,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          },
          "user_tz": -345
        },
        "id": "0VyuzIpXtvWI",
        "outputId": "4b92cc19-a949-4058-89e3-845882865ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Qr-Mt4sdt0tm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967298408,
          "user_tz": -345,
          "elapsed": 44,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,  # T4 can handle this for BERT-base\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=1,              # Save space in Colab\n",
        "    fp16=True,                       # 2x speedup on T4 GPU\n",
        "    dataloader_num_workers=2,        # Colab has limited CPU cores\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",                # Disable wandb/tensorboard if not needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Pi-FVYQsuWiI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967300392,
          "user_tz": -345,
          "elapsed": 113,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "MxyFD9kCuoUX",
        "outputId": "0da64b16-2c1e-4b28-e301-4d3cc01e954c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2346/2346 19:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.208500</td>\n",
              "      <td>0.197783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.139100</td>\n",
              "      <td>0.215994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.097800</td>\n",
              "      <td>0.237506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2346, training_loss=0.16536663539980784, metrics={'train_runtime': 1170.2021, 'train_samples_per_second': 64.091, 'train_steps_per_second': 2.005, 'total_flos': 9935054899200000.0, 'train_loss': 0.16536663539980784, 'epoch': 3.0})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(tokenized_datasets[\"test\"][\"label\"], preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "q8i-KeA-00g_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967698456,
          "user_tz": -345,
          "elapsed": 107405,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "1d2f83a8-a7e5-42ca-b8b3-f63340d7361e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00     12500\n",
            "           1       0.50      1.00      0.67     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.50      0.50      0.33     25000\n",
            "weighted avg       0.50      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(tokenized_datasets[\"train\"][\"label\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx0KcHterLmC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763967946048,
          "user_tz": -345,
          "elapsed": 2010,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "89a87d2c-419d-49f2-cee6-b2d425ca4321"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 12500, 1: 12500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if loss decreased during training\n",
        "for log in trainer.state.log_history:\n",
        "    if 'loss' in log:\n",
        "        print(f\"Step {log.get('step', 'N/A')}: Loss = {log['loss']:.4f}\")"
      ],
      "metadata": {
        "id": "dcq2nd3tr5gv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763968020539,
          "user_tz": -345,
          "elapsed": 5,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        }
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if model is actually trained\n"
      ],
      "metadata": {
        "id": "b3KJ7IkssQBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text=[\"This movie is absolutely wonderful and amazing!\",\n",
        "    \"This movie is terrible and boring.\"]\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # Corrected model name\n",
        "inputs=tokenizer(sample_text,padding=True,truncation=True, return_tensors=\"pt\") # Corrected variable name from sample_texts to sample_text\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model=model.cuda()\n",
        "  inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "outputs = model(**inputs)\n",
        "probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "print(\"Predictions:\")\n",
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "eafd1ee5185b4ae2b10f26a1aa4270b2",
            "b136f23759054a9393fa4aed0acce42b",
            "336d43d7aaf74649a8c04180a9a67a85",
            "826f3bc6c43644b3aef70e2e02eea3f1",
            "c5b0cd51e26645f98ddb4536bd2ae31e",
            "4cc6cb23fd59481d8486ecf788b0fcad",
            "a97375f5868d41b597b83c253442b03e",
            "1e11f16cecf84f73b280f3ea431acc5f",
            "f5ca0f27d3694b729265965f8f649b74",
            "2306fbab1c384111b3852c63b9b83db3",
            "d7713a2a47cb43d9a2e3de9e60c0d6b6",
            "54eaeccfda794f4ba5025ddb77afe781",
            "5666cce390be4dceb574abbf93f7659d",
            "e436114ae5834783b165bf48aa0d4f50",
            "7c3a308d060647bcab7380b2c7017a0a",
            "f0ac6cb4c8a642d58a58e914e31e734f",
            "721b41c70b3e49b0a4980693b775278c",
            "a066fc2a84e243ae8c3b1e39eee0a915",
            "9a0e326fb8e548749467b17d8061f4ad",
            "29c8a3c98541480aa0d1b74968f5cf0b",
            "4842addc45ca492f9a9a41827d7a11c5",
            "2644fe18d89c43cd9287c7305a005472",
            "f37e9fa8cfca4976aa46d2eafea1d746",
            "a220bd9f88504b959bfded3e2b63d1ca",
            "df346e483f914e9b877a35ba3db49e87",
            "a7383ef61c2a416386eb5a5b28be89e2",
            "919ae2bf2ab543e097d6a5bab9f6ed4f",
            "2b4354caa36f4ef98d8f44fe535eccab",
            "efbabc5b69c74e1a90fea98b7f486bf5",
            "cc90729874ac413da00142d30651f2cb",
            "7a6d8896d75e4c3ca151c337faf5f213",
            "1765723bab8f4512ab45ecfa3c00d1a9",
            "338627180146471fb164ee9386ccc43c"
          ]
        },
        "id": "779lraOOsZWt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763968380224,
          "user_tz": -345,
          "elapsed": 2013,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "f91b81b8-6d36-49fb-d857-338ae6773548"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eafd1ee5185b4ae2b10f26a1aa4270b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54eaeccfda794f4ba5025ddb77afe781"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f37e9fa8cfca4976aa46d2eafea1d746"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "tensor([[0.4686, 0.5314],\n",
            "        [0.4568, 0.5432]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start fresh with a new model\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "# Reinitialize the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Move to GPU\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Better training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"steps\",           # Evaluate more frequently\n",
        "    eval_steps=200,                  # Check progress every 200 steps\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,  # Safer batch size\n",
        "    num_train_epochs=4,              # More epochs\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,                # See progress\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=400,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True,\n",
        "    warmup_steps=500,                # Gradual learning rate warmup\n",
        ")\n",
        "\n",
        "# Add evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'f1': f1_score(labels, preds, average='weighted')\n",
        "    }\n",
        "\n",
        "# Create new trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and watch the metrics\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eYZwbPOAulx6",
        "executionInfo": {
          "status": "error",
          "timestamp": 1763974896995,
          "user_tz": -345,
          "elapsed": 6142283,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "e7deae2e-26da-4aa0-a6f9-644b62c228bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mselimaharjan33\u001b[0m (\u001b[33mselimaharjan33-st-xavier-s-college-nepal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251124_071953-reukxqi3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface/runs/reukxqi3' target=\"_blank\">scarlet-sunset-3</a></strong> to <a href='https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface' target=\"_blank\">https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface/runs/reukxqi3' target=\"_blank\">https://wandb.ai/selimaharjan33-st-xavier-s-college-nepal/huggingface/runs/reukxqi3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4001' max='6252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4001/6252 1:39:18 < 55:53, 0.67 it/s, Epoch 2.56/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>0.311156</td>\n",
              "      <td>0.884600</td>\n",
              "      <td>0.884291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.271900</td>\n",
              "      <td>0.235719</td>\n",
              "      <td>0.910200</td>\n",
              "      <td>0.910051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.221832</td>\n",
              "      <td>0.911320</td>\n",
              "      <td>0.911100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.228200</td>\n",
              "      <td>0.211718</td>\n",
              "      <td>0.925520</td>\n",
              "      <td>0.925511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.266700</td>\n",
              "      <td>0.256774</td>\n",
              "      <td>0.911040</td>\n",
              "      <td>0.910749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.239200</td>\n",
              "      <td>0.198081</td>\n",
              "      <td>0.928920</td>\n",
              "      <td>0.928876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.200700</td>\n",
              "      <td>0.213546</td>\n",
              "      <td>0.930720</td>\n",
              "      <td>0.930692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.170700</td>\n",
              "      <td>0.226835</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.928948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>0.307646</td>\n",
              "      <td>0.926720</td>\n",
              "      <td>0.926639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.153400</td>\n",
              "      <td>0.250602</td>\n",
              "      <td>0.931560</td>\n",
              "      <td>0.931523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.140500</td>\n",
              "      <td>0.290265</td>\n",
              "      <td>0.926120</td>\n",
              "      <td>0.925990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.140600</td>\n",
              "      <td>0.219754</td>\n",
              "      <td>0.936680</td>\n",
              "      <td>0.936676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.162700</td>\n",
              "      <td>0.208008</td>\n",
              "      <td>0.937400</td>\n",
              "      <td>0.937381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.152400</td>\n",
              "      <td>0.203354</td>\n",
              "      <td>0.937680</td>\n",
              "      <td>0.937678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.148300</td>\n",
              "      <td>0.208947</td>\n",
              "      <td>0.939600</td>\n",
              "      <td>0.939592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.043900</td>\n",
              "      <td>0.266939</td>\n",
              "      <td>0.940360</td>\n",
              "      <td>0.940360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.292751</td>\n",
              "      <td>0.940440</td>\n",
              "      <td>0.940438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.271488</td>\n",
              "      <td>0.937440</td>\n",
              "      <td>0.937439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.082900</td>\n",
              "      <td>0.275795</td>\n",
              "      <td>0.938800</td>\n",
              "      <td>0.938796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2108' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2108/3125 02:15 < 01:05, 15.55 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-67865783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Train and watch the metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2754\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2757\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4705\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4707\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4708\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4709\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m         \"\"\"\n\u001b[0;32m-> 3100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_torch_compile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# Then pad to the maximum size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what checkpoints were saved\n",
        "import os\n",
        "import torch # Import torch to use .cuda()\n",
        "\n",
        "checkpoints = [d for d in os.listdir('./results') if d.startswith('checkpoint')]\n",
        "print(\"Saved checkpoints:\", sorted(checkpoints))\n",
        "\n",
        "# Load the best one (around step 1200)\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "best_model = AutoModelForSequenceClassification.from_pretrained('./results/checkpoint-1200')\n",
        "\n",
        "# Explicitly move the loaded model to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    best_model = best_model.cuda()\n",
        "\n",
        "# Now evaluate with this model\n",
        "trainer.model = best_model\n",
        "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(tokenized_datasets[\"test\"][\"label\"], preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "CiRNDNdkGSn_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763975722478,
          "user_tz": -345,
          "elapsed": 747181,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "faef94ae-2174-46f1-fcdd-f3078a4de520"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoints: ['checkpoint-1200', 'checkpoint-1600', 'checkpoint-2000', 'checkpoint-2400', 'checkpoint-2800', 'checkpoint-3200', 'checkpoint-3600', 'checkpoint-400', 'checkpoint-800']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4001' max='6252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4001/6252 1:39:18 < 55:53, 0.67 it/s, Epoch 2.56/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>0.311156</td>\n",
              "      <td>0.884600</td>\n",
              "      <td>0.884291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.271900</td>\n",
              "      <td>0.235719</td>\n",
              "      <td>0.910200</td>\n",
              "      <td>0.910051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.221832</td>\n",
              "      <td>0.911320</td>\n",
              "      <td>0.911100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.228200</td>\n",
              "      <td>0.211718</td>\n",
              "      <td>0.925520</td>\n",
              "      <td>0.925511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.266700</td>\n",
              "      <td>0.256774</td>\n",
              "      <td>0.911040</td>\n",
              "      <td>0.910749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.239200</td>\n",
              "      <td>0.198081</td>\n",
              "      <td>0.928920</td>\n",
              "      <td>0.928876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.200700</td>\n",
              "      <td>0.213546</td>\n",
              "      <td>0.930720</td>\n",
              "      <td>0.930692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.170700</td>\n",
              "      <td>0.226835</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.928948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>0.307646</td>\n",
              "      <td>0.926720</td>\n",
              "      <td>0.926639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.153400</td>\n",
              "      <td>0.250602</td>\n",
              "      <td>0.931560</td>\n",
              "      <td>0.931523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.140500</td>\n",
              "      <td>0.290265</td>\n",
              "      <td>0.926120</td>\n",
              "      <td>0.925990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.140600</td>\n",
              "      <td>0.219754</td>\n",
              "      <td>0.936680</td>\n",
              "      <td>0.936676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.162700</td>\n",
              "      <td>0.208008</td>\n",
              "      <td>0.937400</td>\n",
              "      <td>0.937381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.152400</td>\n",
              "      <td>0.203354</td>\n",
              "      <td>0.937680</td>\n",
              "      <td>0.937678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.148300</td>\n",
              "      <td>0.208947</td>\n",
              "      <td>0.939600</td>\n",
              "      <td>0.939592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.043900</td>\n",
              "      <td>0.266939</td>\n",
              "      <td>0.940360</td>\n",
              "      <td>0.940360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.292751</td>\n",
              "      <td>0.940440</td>\n",
              "      <td>0.940438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.271488</td>\n",
              "      <td>0.937440</td>\n",
              "      <td>0.937439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.082900</td>\n",
              "      <td>0.275795</td>\n",
              "      <td>0.938800</td>\n",
              "      <td>0.938796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5233' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 16:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.93     12500\n",
            "           1       0.91      0.95      0.93     12500\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.93      0.93      0.93     25000\n",
            "weighted avg       0.93      0.93      0.93     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to make prediction faster next time:\n",
        "\n",
        "best_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    './results/checkpoint-1200',\n",
        "    torch_dtype=torch.float16\n",
        ").to('cuda')"
      ],
      "metadata": {
        "id": "0d-blRO1JNWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "text=\"I love this food.\"\n",
        "inputs=tokenizer(text,return_tensors=\"pt\")\n",
        "\n",
        "# Move to GPU\n",
        "if torch.cuda.is_available():\n",
        "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "    model = model.cuda()\n",
        "\n",
        "label_map={\n",
        "    0:\"Negative\",\n",
        "    1:\"Positive\"\n",
        "}\n",
        "\n",
        "with torch.no_grad(): #only predicting, not training\n",
        "  pred=(best_model(**inputs).logits.argmax().item())\n",
        "print(\"Prediction is:\",label_map[pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RErviSngJRAy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763977628079,
          "user_tz": -345,
          "elapsed": 505,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "e66ea814-a2b2-45a2-b7b8-080c13c1401d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction is: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inputs expands it into:**\n",
        "\n",
        "best_model(input_ids=..., attention_mask=...)\n",
        "\n",
        "**.logits**\n",
        "\n",
        "The model output contains raw prediction scores for each class.\n",
        "\n",
        "Example:\n",
        "\n",
        "logits = [[1.2, -0.3]]\n",
        "\n",
        "\n",
        "These are NOT probabilities \u2014 just scores.\n",
        "\n",
        "**.argmax()**\n",
        "\n",
        "Finds the index of the highest score.\n",
        "\n",
        "Example:\n",
        "\n",
        "[1.2, -0.3] \u2192 highest is 1.2 \u2192 index = 0\n",
        "\n",
        "\n",
        "So your model predicted class 0.\n",
        "\n",
        "**.item()**\n",
        "\n",
        "Convert PyTorch tensor \u2192 normal Python number.\n",
        "\n",
        "Example:\n",
        "\n",
        "tensor(0) \u2192 0 (Python integer)"
      ],
      "metadata": {
        "id": "nBcSSyQsOZIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/seli33/Fine-Tuning-BERT-for-Sentiment-Analysis.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR6PlzKJOuN3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763977782405,
          "user_tz": -345,
          "elapsed": 1350,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "4e11c564-9e55-4035-9309-a106173d6d71"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'Fine-Tuning-BERT-for-Sentiment-Analysis'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Fine-Tuning-BERT-for-Sentiment-Analysis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZohBtiRpO_9R",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763977814634,
          "user_tz": -345,
          "elapsed": 44,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "e34896fe-0831-4956-cb32-0654566d3ac7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fine-Tuning-BERT-for-Sentiment-Analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Fine-Tuning-BERT-for-Sentiment-Analysis\n",
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lfzQyc8Rtmr",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763977913835,
          "user_tz": -345,
          "elapsed": 127,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "8ebba88f-d3b2-4842-bf0d-44724013cd87"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fine-Tuning-BERT-for-Sentiment-Analysis\n",
            "On branch main\n",
            "\n",
            "No commits yet\n",
            "\n",
            "nothing to commit (create/copy files and use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgYAojHURzg4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763978159675,
          "user_tz": -345,
          "elapsed": 149,
          "user": {
            "displayName": "Selina Maharjan",
            "userId": "04943077583300553975"
          }
        },
        "outputId": "687a7d4a-4fa7-4637-a0ef-c204f3f7b3c2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " basics.ipynb  'Copy of model_training.ipynb'   model_training.ipynb\n",
            " BERT.ipynb     FineTuning.ipynb\t        Untitled0.ipynb\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP/OnjEMOg4Tch8Vc87WR5M"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}